{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2bbd74e-811e-4204-8774-dad45cc5443e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Proyecto 4: Faces in The Wild\n",
    "\n",
    "**Integrantes**:\n",
    "- Lucas Carranza\n",
    "- David Herencia\n",
    "- Kalos Lazo\n",
    "- Lenin Chavez"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73349589-35b9-4e73-b077-3dd4b498a308",
   "metadata": {},
   "source": [
    "# **Triplet Neural Network**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f57b0db-2874-40c2-bc1f-458b0dc9bd97",
   "metadata": {},
   "source": [
    "---\n",
    "### **1. Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e082768-5189-4b78-8ac9-b2763ab1feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from torchvision import transforms as transforms, datasets, models\n",
    "from torchvision.models import alexnet, AlexNet_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8203b75b-0b52-4c11-99b8-b22a2555ab81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1272b7f4-a02e-4e07-869e-e8b7a61d8c39",
   "metadata": {},
   "source": [
    "---\n",
    "## **2. Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c9b8184-473a-4bab-b6b7-93e82041a5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     anchor positive negative\n",
      "0      1485     4047       84\n",
      "1     10796     3696     8731\n",
      "2      7003     2539     1093\n",
      "3      8884     9008    10113\n",
      "4      5320    11038    12340\n",
      "...     ...      ...      ...\n",
      "1095  11571     6594     5398\n",
      "1096   1766     9118    12368\n",
      "1097   2613    12250     7879\n",
      "1098  10580     4391      618\n",
      "1099   4677     2901    10154\n",
      "\n",
      "[1100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def generate_triplets(df):\n",
    "    # Crear diccionarios para almacenar pares de imágenes por etiqueta\n",
    "    pairs = {'same': [], 'diff': []}\n",
    "    for _, row in df.iterrows():\n",
    "        pairs[row['label']].append((row['image1'], row['image2']))\n",
    "    \n",
    "    triplets = []\n",
    "    # Iterar sobre cada par 'same' para formar tripletas\n",
    "    for anchor_positive in pairs['same']:\n",
    "        anchor, positive = anchor_positive\n",
    "        \n",
    "        # Evitar seleccionar un negativo que podría ser confusamente similar a las imágenes 'same'\n",
    "        if len(pairs['diff']) > 0:\n",
    "            diff_pair = random.choice(pairs['diff'])\n",
    "            negative = random.choice(diff_pair)  # Elegir al azar una imagen de un par 'diff'\n",
    "\n",
    "            triplets.append({'anchor': anchor, 'positive': positive, 'negative': negative})\n",
    "\n",
    "    return pd.DataFrame(triplets)\n",
    "\n",
    "# Preparar DataFrame\n",
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "train_df[['image1', 'image2']] = train_df['image1_image2'].str.split('_', expand=True)\n",
    "train_df.drop(columns=['image1_image2'], inplace=True)\n",
    "train_df['label'] = ['same' if i % 2 == 0 else 'diff' for i in range(len(train_df))]\n",
    "\n",
    "triplet_df = generate_triplets(train_df)\n",
    "print(train_df)\n",
    "print(triplet_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4308cb-027e-4de1-bf95-16bb61a3422d",
   "metadata": {},
   "source": [
    "---\n",
    "## **3. Custom dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fce759-a22b-4826-9f54-0c0ecddeef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletImageDataset(Dataset):\n",
    "    def __init__(self, df, root_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        anchor_file = f\"{row['anchor']}.png\"\n",
    "        positive_file = f\"{row['positive']}.png\"\n",
    "        negative_file = f\"{row['negative']}.png\"\n",
    "\n",
    "        anchor_path = os.path.join(self.root_dir, anchor_file)\n",
    "        positive_path = os.path.join(self.root_dir, positive_file)\n",
    "        negative_path = os.path.join(self.root_dir, negative_file)\n",
    "        \n",
    "        anchor_img = Image.open(anchor_path).convert('RGB')\n",
    "        positive_img = Image.open(positive_path).convert('RGB')\n",
    "        negative_img = Image.open(negative_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            anchor_img = self.transform(anchor_img)\n",
    "            positive_img = self.transform(positive_img)\n",
    "            negative_img = self.transform(negative_img)\n",
    "\n",
    "        return anchor_img, positive_img, negative_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c92e31-9a7a-427c-a9d1-837fb75c8e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = './images'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_df, validation_df = train_test_split(triplet_df, test_size = 0.2, random_state = 42)\n",
    "train_dataset = TripletImageDataset(train_df, data_root, transform = transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n",
    "\n",
    "validation_dataset = TripletImageDataset(validation_df, data_root, transform = transform)\n",
    "validation_dataloader = DataLoader(validation_dataset, batch_size = 64, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e1ffb-9ff6-4e7b-944f-44f11df60d8f",
   "metadata": {},
   "source": [
    "---\n",
    "## **4. Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14367e1-c635-4987-b80e-63265d4453f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TripletNetwork, self).__init__()\n",
    "        alexnet = models.alexnet(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(alexnet.children())[:-1])\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256 * 6 * 6, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.20),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "        )\n",
    "\n",
    "    def forward(self, anchor, positive, negative):\n",
    "        anchor = self.feature_extractor(anchor).view(anchor.size(0), -1)\n",
    "        anchor = self.fc(anchor)\n",
    "        positive = self.feature_extractor(positive).view(positive.size(0), -1)\n",
    "        positive = self.fc(positive)\n",
    "        negative = self.feature_extractor(negative).view(negative.size(0), -1)\n",
    "        negative = self.fc(negative)\n",
    "        return anchor, positive, negative\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TripletNetwork().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.TripletMarginLoss(margin=0.5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5e26ad-322d-4deb-9db1-ff5b577ba901",
   "metadata": {},
   "source": [
    "---\n",
    "## **5. Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e34ee68-88fb-47dc-934c-071ee051d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, loss_fn, optimizer, num_epochs=25):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (anchor, positive, negative) in enumerate(train_loader):\n",
    "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "            anchor_out, positive_out, negative_out = model(anchor, positive, negative)\n",
    "            loss = loss_fn(anchor_out, positive_out, negative_out)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 10 == 0:\n",
    "                print(f'Epoch {epoch+1}, Step {i+1}, Loss: {loss.item()}')\n",
    "        scheduler.step()\n",
    "\n",
    "train_model(model, train_dataloader, loss_fn, optimizer, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78700ee-9e9b-4375-aff3-89e18142021d",
   "metadata": {},
   "source": [
    "---\n",
    "## **6. Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fea749-9f85-4c8c-a30b-c446c83e9b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_distances(model, dataloader):\n",
    "    model.eval()\n",
    "    pos_distances = []\n",
    "    neg_distances = []\n",
    "    with torch.no_grad():\n",
    "        for anchors, positives, negatives in dataloader:\n",
    "            anchors = anchors.to(device)\n",
    "            positives = positives.to(device)\n",
    "            negatives = negatives.to(device)\n",
    "            anchor_out, positive_out, negative_out = model(anchors, positives, negatives)\n",
    "            \n",
    "            pos_dist = torch.norm(anchor_out - positive_out, p=2, dim=1)\n",
    "            neg_dist = torch.norm(anchor_out - negative_out, p=2, dim=1)\n",
    "            pos_distances.extend(pos_dist.cpu().numpy())\n",
    "            neg_distances.extend(neg_dist.cpu().numpy())\n",
    "    \n",
    "    return np.array(pos_distances), np.array(neg_distances)\n",
    "\n",
    "def calculate_metrics(pos_distances, neg_distances, threshold):\n",
    "    tp = sum(d < threshold for d in pos_distances)\n",
    "    fn = sum(d >= threshold for d in pos_distances)\n",
    "    tn = sum(d >= threshold for d in neg_distances)\n",
    "    fp = sum(d < threshold for d in neg_distances)\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "    \n",
    "pos_distances, neg_distances = extract_features_and_distances(model, train_dataloader)\n",
    "\n",
    "thresholds = np.linspace(min(np.min(pos_distances), np.min(neg_distances)), max(np.max(pos_distances), np.max(neg_distances)), 100)\n",
    "metrics = [calculate_metrics(pos_distances, neg_distances, t) for t in thresholds]\n",
    "\n",
    "best_idx = np.nanargmax([m[3] for m in metrics])  # F1 score está en la posición 3\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_accuracy, best_precision, best_recall, best_f1 = metrics[best_idx]\n",
    "\n",
    "print(f\"Best threshold: {best_threshold:.2f}\")\n",
    "print(f\"Accuracy: {best_accuracy:.2f}, Precision: {best_precision:.2f}, Recall: {best_recall:.2f}, F1 Score: {best_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390620ea-3ec7-4d75-a558-6dc7a07a1257",
   "metadata": {},
   "source": [
    "---\n",
    "## **6. Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99792753-29a7-4e6b-b871-bda4cb685c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../input/dataset/test.csv\")\n",
    "test_df[['anchor', 'positive']] = test_df['image1_image2'].str.split('_', expand = True)\n",
    "\n",
    "test_dataset = TestTripletDataset(test_df, data_root, transform = transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = 64, shuffle = False)\n",
    "\n",
    "def evaluate_and_generate_submission(model, dataloader, threshold = 0.5):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for anchors, positives, negatives in dataloader:\n",
    "            anchors = anchors.to(device)\n",
    "            positives = positives.to(device)\n",
    "            negatives = negatives.to(device)\n",
    "            anchor_out, positive_out, negative_out = model(anchors, positives, negatives)\n",
    "            \n",
    "            pos_dist = torch.norm(anchor_out - positive_out, p = 2, dim = 1)\n",
    "            neg_dist = torch.norm(anchor_out - negative_out, p = 2, dim = 1)\n",
    "            predictions.extend([\"same\" if d < threshold else \"diff\" for d in pos_dist])\n",
    "    \n",
    "    submission_df = pd.DataFrame({\n",
    "        'image1_image2': test_df['image1_image2'],\n",
    "        'label': predictions\n",
    "    })\n",
    "    submission_df.to_csv('submission.csv', index = False)\n",
    "    print(\"Results saved to submission.csv\")\n",
    "\n",
    "evaluate_and_generate_submission(model, test_dataloader, threshold = best_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
