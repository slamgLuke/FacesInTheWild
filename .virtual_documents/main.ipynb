


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import math
from PIL import Image

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim.lr_scheduler import StepLR
from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler

import torchvision
from torchvision import transforms, datasets


# Para mac silicon chip
device = torch.device('mps')
print(f"using device: {device}")





train_df = pd.read_csv("train.csv")
test_df = pd.read_csv("test.csv")

# Split the 'image1_image2' column into two columns
train_df[['image1', 'image2']] = train_df['image1_image2'].str.split('_', expand=True)
test_df[['image1', 'image2']] = test_df['image1_image2'].str.split('_', expand=True)

# Drop the original 'image1_image2' column
train_df.drop(columns=['image1_image2'], inplace=True)
test_df.drop(columns=['image1_image2'], inplace=True)

# Reorder cols
train_df = train_df[['image1', 'image2', 'label']]

# Convert label image to number
# diff = 0
# same = 1
#train_df['label'] = pd.factorize(train_df['label'])[0]

#train_df.head()

train_df['label'] = train_df['label'].apply(lambda x: 0 if x == 'diff' else 1)

# Imprimir la cantidad de ceros y unos
label_counts = train_df['label'].value_counts()
print(label_counts)

# Generar un gráfico de barras
label_counts.plot(kind='bar', color=['blue', 'orange'])
plt.title('Frecuencia de etiquetas en el conjunto de entrenamiento')
plt.xlabel('Etiqueta')
plt.ylabel('Frecuencia')
plt.xticks(ticks=[0, 1], labels=['Same (1)', 'Diff (0)'])
plt.show()

train_df.head()


# Helper functions to load images from dataset and plot them
image_path = "cropped_faces_2"

def load_img(img_id):
    path = f"{image_path}/{img_id}.png"
    return Image.open(path)

def plot_imgs(imgs, size=3):
    img_number = imgs.shape[0]
    rows = cols = math.ceil(np.sqrt(img_number))
    fig = plt.figure(figsize=(rows*size, cols*size))
    for i in range(img_number):
        fig.add_subplot(rows, cols, i+1)
        plt.imshow(imgs[i])
        plt.axis('off')
    plt.show()

def visualize_samples(loader, num_samples=5, size=3):
    rows = cols = math.ceil(np.sqrt(num_samples))
    fig = plt.figure(figsize=(rows*size, cols*size))
    for images1, images2, labels in loader:
        for i in range(num_samples):
            plt.subplot(rows, cols, i+1)
            image = images1[i].permute(1, 2, 0).cpu().numpy()  # Change (C, H, W) to (H, W, C) and convert to numpy array
            plt.imshow(image)
            plt.axis('off')
        break
    plt.show()


# Example on how to load and plot images
im1 = load_img(train_df['image1'][1347])
im2 = load_img(train_df['image2'][1347])
plot_imgs(np.array([im1, im2]))

np.array(im1).shape # Imagenes de 64x64 en formato RGB








class TwoImageDataset(Dataset):
    def __init__(self, df, transform=None, is_test=False):
        self.df = df
        self.transform = transform
        self.is_test = is_test

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img1_id = self.df.iloc[idx, 0]
        img2_id = self.df.iloc[idx, 1]

        img1 = load_img(img1_id).convert('RGB')
        img2 = load_img(img2_id).convert('RGB')
        
        if self.transform:
            img1 = self.transform(img1)
            img2 = self.transform(img2)

        if self.is_test:
            return img1, img2
            
        label = self.df.iloc[idx, 2]
        return img1, img2, torch.tensor(label, dtype=torch.float32)


import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torchvision import transforms
from torch.utils.data import DataLoader
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import pandas as pd
from torchvision.utils import make_grid
from torchvision import transforms
from imgaug import augmenters as iaa
import imgaug as ia

class ImgAugTransform:
    def __init__(self):
        self.aug = iaa.Sequential([
            #iaa.Resize((64, 64)),
            #iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 3.0))),
            iaa.Fliplr(0.5),
            iaa.Affine(rotate=(-20, 20), mode='symmetric'),
            #iaa.Sometimes(0.25,
                          #iaa.OneOf([iaa.Dropout(p=(0, 0.1)),
                              #       iaa.CoarseDropout(0.1, size_percent=0.5)])),
            iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)
        ])
      
    def __call__(self, img):
        img = np.array(img)
        return self.aug.augment_image(img)

tfs = transforms.Compose([
    ImgAugTransform(),
    transforms.ToTensor()
])

batch_size = 64

# Definir las transformaciones de augmentación de datos
data_augmentation_transforms = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.GaussianBlur(kernel_size=3,sigma=(0.1, 1.0)),
    transforms.ColorJitter(brightness=0.3, contrast=1, saturation=0.2),
    transforms.ToTensor(),  # Convert the image to a PyTorch tensor
])


# Define validation/test transformations
val_test_transforms = transforms.Compose([
    transforms.ToTensor(),
])

# Train-Test split
train_subset_df, val_subset_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=12)


# Initializing custom datasets with transformations
train_dataset = TwoImageDataset(train_subset_df, transform=data_augmentation_transforms)
val_dataset = TwoImageDataset(val_subset_df, transform=val_test_transforms)
test_dataset = TwoImageDataset(test_df, transform=val_test_transforms, is_test=True)

# Initialize the DataLoaders
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)
test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)



def show_dataset(dataset, n=10):

    imgs = torch.stack([dataset[i][0] for _ in range(n)
                       for i in range(9)])
    grid = make_grid(imgs).numpy()
    plt.imshow(np.transpose(grid, (1, 2, 0)), interpolation='nearest')
    plt.axis('off')

show_dataset(train_dataset)




from torchvision import models

class SiameseNeuralNetwork(nn.Module):
    def __init__(self):
        super(SiameseNeuralNetwork, self).__init__()

        # instance of resnet, get pretrained weights, take all except classification layer
        # alexnet = models.alexnet(weights = models.AlexNet_Weights.IMAGENET1K_V1)
        regnet = models.resnet152(weights=models.ResNet152_Weights.DEFAULT)
        self.conv1 = nn.Sequential(*list(regnet.children())[:-1])

        # fully connected layers, executed after alexnet weights
        self.fc = nn.Sequential(
            # at the end of alexnet there is 256 channels and 6x6 dimensions after pooling, multiply 2 times cause of siamese
            # at the end transform the input features in a 512 vector of w
            nn.Linear(in_features = 4096, out_features = 4096, bias = True),
            nn.BatchNorm1d(4096), # normalize layer for median 0 and variance 1 (mitigate gradient error)
            nn.LeakyReLU(negative_slope = 0.01), # non-linear activation function, 
            #nn.Dropout(0.20),
            nn.Linear(4096, 4096),
            nn.BatchNorm1d(4096),
            nn.LeakyReLU(negative_slope = 0.01),
            #nn.Dropout(0.20),
            nn.Linear(4096, 1),
            nn.Sigmoid()
        )

    def forward_once(self, x):
        
        x = self.conv1(x)
        x = x.view(x.size(0), -1)
        return x

    def forward(self, img1, img2):

        out1 = self.forward_once(img1)
        out2 = self.forward_once(img2)
        # print(out1.shape)
        
        concat = torch.cat((out1, out2), 1)
        # print(concat.shape)
        
        output = self.fc(concat)
        output = torch.flatten(output)
        # print(output)
        return output

    def train_cnn(self, train_loader, loss_fn, optimizer, scheduler=None, num_epochs=5):
        total_step = len(train_loader)
        list_loss = []
        for epoch in range(num_epochs):
            model.train()
            epoch_loss = 0  # Variable para acumular la pérdida de la época
            for i, (images1, images2, labels) in enumerate(train_loader):
                images1 = images1.to(device)
                images2 = images2.to(device)
                labels = labels.to(device)
    
                output = self(images1, images2)
                loss = loss_fn(output, labels)
    
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
    
                epoch_loss += loss.item()  # Acumula la pérdida
                list_loss.append(loss.item())
                i += 1
    
                if (i + 1) % 10 == 0:
                    print('Epoch [{}/{}], Step [{}/{}], Loss: {}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))
    
            if scheduler:
                scheduler.step()
    
        print('Finished Training Trainset')
        return list_loss
    
    def predict(self, dataloader, with_labels=False):
        y_pred = []
        model.eval()
        with torch.no_grad():
            if not with_labels:
                for image1, image2 in dataloader:
                    image1, image2 = image1.to(device), image2.to(device)
                    output = self(image1, image2)
                    output = output.cpu()
                    pred = torch.round(output)
                    y_pred.append(int(pred.item()))
            else:
                for image1, image2, _ in dataloader:
                    image1, image2 = image1.to(device), image2.to(device)
                    output = self(image1, image2)
                    output = output.cpu()
                    pred = torch.round(output)
                    y_pred.append(int(pred.item()))
            return y_pred


torch.mps.empty_cache()
learning_rate = 1e-4
model = SiameseNeuralNetwork().to(device)

loss_fn = nn.BCELoss()

optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

scheduler = StepLR(optimizer=optimizer, step_size=20, gamma=0.1)







torch.mps.empty_cache()
epochs = 20

# Entrenamiento del modelo0
list_loss = model.train_cnn(train_dataloader, loss_fn, optimizer, scheduler=scheduler, num_epochs=epochs)


import gc

gc.collect() 
torch.mps.empty_cache()


# Plot the loss function
plt.figure(figsize=(10, 5))
plt.plot(list_loss, label='Training Loss', color='blue')
plt.title('Training Loss Over Iterations')
plt.xlabel('Iteration')

plt.ylabel('Loss')
plt.show()


from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report

val_pred = model.predict(val_dataloader, with_labels=True)
cm = confusion_matrix(val_subset_df['label'], val_pred, normalize='true')

# Generate the classification report
report = classification_report(val_subset_df['label'], val_pred)
print("Classification Report:")
print(report)

# Plot the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['different', 'same'])
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()


test_values = model.predict(test_dataloader)
print(np.unique(test_values))


test_df_p4 = pd.read_csv("test.csv")  # Asegúrate de que tienes un archivo test.csv cargado

# Crear el DataFrame para la sumisión
submission_df = pd.DataFrame({
    'image1_image2': test_df_p4['image1_image2'],
    'label': ['same' if pred == 1 else 'diff' for pred in test_values]
})

# Guardar el DataFrame en un archivo CSV
submission_df.to_csv('submission_p4.csv', index=False)

print("Submission saved to submission_p4.csv")





from facenet_pytorch import InceptionResnetV1


# Create an inception resnet (in eval mode):
resnet = InceptionResnetV1(pretrained='vggface2').eval()
print(nn.Sequential(*list(resnet.children())[:]))



from facenet_pytorch import InceptionResnetV1

class SNN(nn.Module):
    def __init__(self):
        super(SNN, self).__init__()
        self.resnet = InceptionResnetV1(pretrained='vggface2').eval()  # Usar el modelo preentrenado
        self.conv1 = nn.Sequential(*list(resnet.children())[:])
        
        # Congelar todas las capas del modelo Facenet
        for param in self.resnet.parameters():
            param.requires_grad = False
        for param in resnet.block8.parameters():
            param.requires_grad = True
            
        # Capas completamente conectadas después de la extracción de características
        # Salida de 512 por imagen
        self.fc = nn.Sequential(
            nn.Linear(512 * 2, 4096),  # Ajustar el tamaño de entrada
            nn.BatchNorm1d(4096),
            nn.LeakyReLU(negative_slope=0.01),
            nn.Linear(4096, 4096),
            nn.BatchNorm1d(4096),
            nn.LeakyReLU(negative_slope=0.01),
            nn.Linear(4096, 1),
            nn.Sigmoid()
        )

    def forward_once(self, x):
        embeddings = self.resnet(x)
        return embeddings

    def forward(self, img1, img2):
        out1 = self.forward_once(img1)
        out2 = self.forward_once(img2)
        concat = torch.cat((out1, out2), 1)
        output = self.fc(concat)
        return output

    def train_cnn(self, train_loader, loss_fn, optimizer, scheduler=None, num_epochs=5):
        total_step = len(train_loader)
        list_loss = []
        for epoch in range(num_epochs):
            self.train()
            epoch_loss = 0
            for i, (images1, images2, labels) in enumerate(train_loader):
                images1 = images1.to(device)
                images2 = images2.to(device)
                labels = labels.to(device).unsqueeze(1) 

                output = self(images1, images2)
                loss = loss_fn(output, labels)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                epoch_loss += loss.item()
                list_loss.append(loss.item())

                if (i + 1) % 10 == 0:
                    print('Epoch [{}/{}], Step [{}/{}], Loss: {}'.format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))

            if scheduler:
                scheduler.step()

        print('Finished Training Trainset')
        return list_loss

    def predict(self, dataloader, with_labels=False):
        y_pred = []
        self.eval()
        with torch.no_grad():
            if not with_labels:
                for image1, image2 in dataloader:
                    image1, image2 = image1.to(device), image2.to(device)
                    output = self(image1, image2)
                    output = output.cpu()
                    pred = torch.round(output)
                    y_pred.append(int(pred.item()))
            else:
                for image1, image2, _ in dataloader:
                    image1, image2 = image1.to(device), image2.to(device)
                    output = self(image1, image2)
                    output = output.cpu()
                    pred = torch.round(output)
                    y_pred.append(int(pred.item()))
        return y_pred


torch.mps.empty_cache()
learning_rate = 1e-4
model1 = SNN().to(device)

loss_fn = nn.BCELoss()

optimizer = torch.optim.Adam(model1.parameters(), lr=learning_rate)

scheduler = StepLR(optimizer=optimizer, step_size=20, gamma=0.1)


torch.mps.empty_cache()
epochs = 15

# Entrenamiento del modelo0
list_loss = model1.train_cnn(train_dataloader, loss_fn, optimizer, scheduler=scheduler, num_epochs=epochs)


# Plot the loss function
plt.figure(figsize=(10, 5))
plt.plot(list_loss, label='Training Loss', color='blue')
plt.title('Training Loss Over Iterations')
plt.xlabel('Iteration')

plt.ylabel('Loss')
plt.show()


from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report

val_pred = model1.predict(val_dataloader, with_labels=True)
cm = confusion_matrix(val_subset_df['label'], val_pred, normalize='true')

# Generate the classification report
report = classification_report(val_subset_df['label'], val_pred)
print("Classification Report:")
print(report)

# Plot the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['different', 'same'])
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()


test_values = model1.predict(test_dataloader)
print(np.unique(test_values))


test_df_p4 = pd.read_csv("test.csv")  # Asegúrate de que tienes un archivo test.csv cargado

# Crear el DataFrame para la sumisión
submission_df = pd.DataFrame({
    'image1_image2': test_df_p4['image1_image2'],
    'label': ['same' if pred == 1 else 'diff' for pred in test_values]
})

# Guardar el DataFrame en un archivo CSV
submission_df.to_csv('submission_p4.csv', index=False)

print("Submission saved to submission_p4.csv")


# Guardar pesos del Mejor modelo
torch.save(model1.state_dict(), 'snn_model.pth')












