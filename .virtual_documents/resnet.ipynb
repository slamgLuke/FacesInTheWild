





import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import torchvision
import math

from PIL import Image
from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau
from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler
from torchvision import transforms, datasets, models
from sklearn.model_selection import train_test_split





# Nvidia
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')

print(f"Device: {device}")


# Apple mac silicon
device = torch.device('mps' if torch.backends.mps.is_built() else 'cpu')

print(f"Device: {device}")








class ImageHandler:
    def __init__(self, image_path = "cropped_faces"):
        self.image_path = image_path

    def load_img(self, img_id):
        path = f"{self.image_path}/{img_id}.png"
        return Image.open(path)

    def plot_imgs(self, imgs, size = 3):
        img_number = imgs.shape[0]
        rows = cols = math.ceil(np.sqrt(img_number))
        fig = plt.figure(figsize=(rows*size, cols*size))
        for i in range(img_number):
            fig.add_subplot(rows, cols, i+1)
            plt.imshow(imgs[i])
            plt.axis('off')
        plt.show()

    def visualize_samples(self, loader, num_samples = 5, size = 3):
        rows = cols = math.ceil(np.sqrt(num_samples))
        fig = plt.figure(figsize = (rows*size, cols*size))
        for images1, images2, labels in loader:
            for i in range(num_samples):
                plt.subplot(rows, cols, i+1)
                image = images1[i].permute(1, 2, 0).cpu().numpy()  # Change (C, H, W) to (H, W, C) and convert to numpy array
                plt.imshow(image)
                plt.axis('off')
            break
        plt.show()





train_df = pd.read_csv("train.csv")
test_df = pd.read_csv("test.csv")

print('> Train data before image splitting and label encoder');
print(train_df.head())

print('\n> Test data before image splitting and label encoder');
print(test_df.head())





train_df = pd.read_csv("train.csv")
test_df = pd.read_csv("test.csv")

train_df[['image1', 'image2']] = train_df['image1_image2'].str.split('_', expand = True)
test_df[['image1', 'image2']] = test_df['image1_image2'].str.split('_', expand = True)

train_df.drop(columns = ['image1_image2'], inplace = True)
test_df.drop(columns = ['image1_image2'], inplace = True)

train_df = train_df[['image1', 'image2', 'label']]
train_df['label'] = pd.factorize(train_df['label'])[0]


print('> Train data before image splitting and label encoder');
print(train_df.head())

print('\n> Test data before image splitting and label encoder');
print(test_df.head())





print(f'\n> Train data shape: {train_df.shape}')
print(f'> Test data shape: {train_df.shape}')

print('\n> Train data labels with 0:', train_df['label'].value_counts()[0])
print('> Train data labels with 1:', train_df['label'].value_counts()[1])

print('\n> Train data null values:', train_df.isnull().sum().sum())
print('> Test data null values:', test_df.isnull().sum().sum())





ih = ImageHandler()

im1 = ih.load_img(train_df['image1'][1347])
im2 = ih.load_img(train_df['image2'][1347])

ih.plot_imgs(np.array([im1, im2]))
np.array(im1).shape








class TwoImageDataset(Dataset):
    def __init__(self, df, transform = None, is_test = False):
        self.df = df
        self.transform = transform
        self.is_test = is_test

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        img1_id = self.df.iloc[idx, 0]
        img2_id = self.df.iloc[idx, 1]

        img1 = ih.load_img(img1_id).convert('RGB')
        img2 = ih.load_img(img2_id).convert('RGB')
        
        if self.transform:
            img1 = self.transform(img1)
            img2 = self.transform(img2)

        if self.is_test:
            return img1, img2
            
        label = self.df.iloc[idx, 2]
        return img1, img2, torch.tensor(label, dtype = torch.float32)





# parameters
batch_size = 64
transform = transforms.Compose([
    transforms.ToTensor(),
])

# split train and test
train_subset_df, val_subset_df = train_test_split(train_df, test_size = 0.2, stratify = train_df['label'], random_state = 42)

# initialize custom datasets
train_dataset = TwoImageDataset(train_subset_df, transform = transform)
val_dataset = TwoImageDataset(val_subset_df, transform = transform)
test_dataset = TwoImageDataset(test_df, transform = transform, is_test = True)

# initialize custom dataloaders
train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)
val_dataloader = DataLoader(val_dataset, batch_size = 1, shuffle = False)
test_dataloader = DataLoader(test_dataset, batch_size = 1, shuffle = False)

# check dataloader via example
print('> Example dataloaders image visualization\n')
ih.visualize_samples(train_dataloader, 4)





class SiameseNeuralNetwork(nn.Module):
    def __init__(self):
        super(SiameseNeuralNetwork, self).__init__()

        # instance of resnet, get pretrained weights, take all except classification layer
        resnet = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)
        self.conv1 = nn.Sequential(*list(resnet.children())[:-1])

        # fully connected layers, executed after alexnet weights
        self.fc = nn.Sequential(
            # at the end of resnet there is 2048 flatten features per image
            nn.Linear(in_features = 4096, out_features = 4096, bias = True),
            nn.BatchNorm1d(4096), # normalize layer for median 0 and variance 1 (mitigate gradient error)
            nn.LeakyReLU(negative_slope = 0.01), # non-linear activation function, 
            #nn.Dropout(0.20),
            nn.Linear(4096, 4096),
            nn.BatchNorm1d(4096),
            nn.LeakyReLU(negative_slope = 0.01),
            #nn.Dropout(0.20),
            nn.Linear(4096, 1),
            nn.Sigmoid()
        )

    def forward_once(self, x):
        x = self.conv1(x)
        x = x.view(x.size(0), -1)
        return x

    def forward(self, img1, img2):
        out1 = self.forward_once(img1)
        out2 = self.forward_once(img2)
        # print(out1.shape)
        
        concat = torch.cat((out1, out2), 1)
        # print(concat.shape)
        
        output = self.fc(concat)
        output = torch.flatten(output)
        # print(output)
        return output

    def train_cnn(self, train_loader, val_loader, loss_fn, optimizer, scheduler=None, num_epochs=5, patience=5):
        total_step = len(train_loader)
        list_loss = []
        val_loss = []
        best_loss = float('inf')
        epochs_no_improve = 0
        
        for epoch in range(num_epochs):
            self.train()
            epoch_loss = 0.0
            
            for i, (images1, images2, labels) in enumerate(train_loader):
                images1 = images1.to(device)
                images2 = images2.to(device)
                labels = labels.to(device) 
                
                output = self(images1, images2)
                loss = loss_fn(output, labels)

                optimizer.zero_grad()
                loss.backward()
                optimizer.step()

                epoch_loss += loss.item()
                list_loss.append(loss.item())

                if (i + 1) % 100 == 0:
                    print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_step}], Loss: {loss.item():.4f}')
                
            avg_train_loss = epoch_loss / total_step
            avg_val_loss = self.evaluate(val_loader, loss_fn)
            
            scheduler.step()
            print(f'Epoch {epoch + 1}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')
            if avg_val_loss < best_loss:
                best_loss = avg_val_loss
                epochs_no_improve = 0

            else:
                epochs_no_improve += 1
                if epochs_no_improve >= patience:
                    print('Early stopping triggered.')
                    break
        print('Finished Training Trainset')
        return list_loss, val_loss

    def evaluate(self, val_loader, loss_fn):
        y_pred = []
        running_loss = 0.0
        self.eval()
        with torch.no_grad():
            for image1, image2, labels in val_loader:
                image1, image2, labels = image1.to(device), image2.to(device), labels.to(device)
                output = self(image1, image2)
                loss = loss_fn(output, labels)
                running_loss += loss.item()
                output = output.cpu()
                pred = torch.round(output)
                y_pred.append(float(pred.item()))
        avg_val_loss = running_loss / len(val_loader)
        val_loss.append(avg_val_loss.item())
        return avg_val_loss
        
    def predict(self, dataloader, with_labels=False):
        y_pred = []
        model.eval()
        with torch.no_grad():
            if not with_labels:
                for image1, image2 in dataloader:
                    image1, image2 = image1.to(device), image2.to(device)
                    output = self(image1, image2)
                    output = output.cpu()
                    pred = torch.round(output)
                    y_pred.append(int(pred.item()))
            else:
                for image1, image2, _ in dataloader:
                    image1, image2 = image1.to(device), image2.to(device)
                    output = self(image1, image2)
                    output = output.cpu()
                    pred = torch.round(output)
                    y_pred.append(int(pred.item()))
            return y_pred


epochs = 24
learning_rate = 0.0001
loss_fn = nn.BCELoss()

model = SiameseNeuralNetwork().to(device)
optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = 1e-5)
scheduler = StepLR(optimizer = optimizer, step_size = 2, gamma = 0.1)

torch.mps.empty_cache()
#torch.cuda.empty_cache()
list_loss, val_loss = model.train_cnn(train_dataloader, val_dataloader, loss_fn, optimizer, scheduler = scheduler, num_epochs = epochs)


# Plot the loss function
plt.figure(figsize=(10, 5))
plt.plot(list_loss, label='Training Loss', color='blue')
plt.title('Training Loss Over Iterations')
plt.xlabel('Iteration')
plt.ylabel('Loss')
plt.show()





from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report

val_pred = model.predict(val_dataloader, with_labels=True)
cm = confusion_matrix(val_subset_df['label'], val_pred, normalize='true')

# Generate the classification report
report = classification_report(val_subset_df['label'], val_pred)
print("Classification Report:")
print(report)

# Plot the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['different', 'same'])
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()


test_values = model.predict(test_dataloader)
print(np.unique(test_values))





test_df_p4 = pd.read_csv("test.csv")  # Asegúrate de que tienes un archivo test.csv cargado

# Crear el DataFrame para la sumisión
submission_df = pd.DataFrame({
    'image1_image2': test_df_p4['image1_image2'],
    'label': ['same' if pred == 1 else 'diff' for pred in test_values]
})

# Guardar el DataFrame en un archivo CSV
submission_df.to_csv('submission_p4.csv', index=False)

print("Submission saved to submission_p4.csv")















